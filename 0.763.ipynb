{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from html_sanitizer import Sanitizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random as rnd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "\\\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import bs4\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TitlesTrain.csv\")\n",
    "data_1 = pd.read_csv(\"final_parse.csv\")\n",
    "y_train = np.array(data[\"target\"])\n",
    "groups_train = np.array(data[\"group\"])\n",
    "texts = np.array(data[\"information\"])\n",
    "texts_1 = np.array(data_1[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, data_1, left_on='doc_id', right_on='doc_id',how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# for i in range(data.shape[0]):\n",
    "#     #print(data.iloc[i][\"information\"],data.iloc[i][\"word\"])\n",
    "#     texts.append(str(data.iloc[i][\"information\"]) + \" \" + str(data.iloc[i][\"word\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>information</th>\n",
       "      <th>group</th>\n",
       "      <th>target</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ваз 21213   замена подшипник ступица   нива \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15731</td>\n",
       "      <td>15730</td>\n",
       "      <td>тормозной приложение трансмиссия общий пружина...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ваз 2107 опт  сочи  сравнивать цена  купить п...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14829</td>\n",
       "      <td>14828</td>\n",
       "      <td>питание электрооборудование prestige niva кпп ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>купить ступица лад калина2  трансмиссия   пере...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15764</td>\n",
       "      <td>15763</td>\n",
       "      <td>весь аксессуар акпп цена хонда автопутешествие...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>классика 21010   21074 \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17669</td>\n",
       "      <td>17668</td>\n",
       "      <td>center learn models template templates website...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ступица нива   замена подшипник свой рука \\n</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14852</td>\n",
       "      <td>14851</td>\n",
       "      <td>амортизация амортизатор безопасность ваз ваш в...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x                                        information  group  \\\n",
       "0             0     ваз 21213   замена подшипник ступица   нива \\n      1   \n",
       "1             1   ваз 2107 опт  сочи  сравнивать цена  купить п...      1   \n",
       "2             2  купить ступица лад калина2  трансмиссия   пере...      1   \n",
       "3             3                          классика 21010   21074 \\n      1   \n",
       "4             4       ступица нива   замена подшипник свой рука \\n      1   \n",
       "\n",
       "   target  doc_id  Unnamed: 0_y  \\\n",
       "0       0   15731         15730   \n",
       "1       0   14829         14828   \n",
       "2       0   15764         15763   \n",
       "3       0   17669         17668   \n",
       "4       0   14852         14851   \n",
       "\n",
       "                                                word  \n",
       "0  тормозной приложение трансмиссия общий пружина...  \n",
       "1  питание электрооборудование prestige niva кпп ...  \n",
       "2  весь аксессуар акпп цена хонда автопутешествие...  \n",
       "3  center learn models template templates website...  \n",
       "4  амортизация амортизатор безопасность ваз ваш в...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "    if texts[i] is np.nan:\n",
    "        texts[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = np.array(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X_train = vect.fit_transform(np.append(texts, new_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11690,), (16627,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts.shape, new_texts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (manifold, decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28317, 27473)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28317, 27473), (11690,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, groups_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neigh = 25\n",
    "XTrain = []\n",
    "for i in np.unique(groups_train):\n",
    "    X_ = X_train[groups_train == i]\n",
    "    \n",
    "    distMart = sklearn.metrics.pairwise_distances(X_, metric=\"cosine\")\n",
    "    #print(distMart)\n",
    "    meanDist = np.sort(distMart, axis=1)[:,4:neigh]\n",
    "    lis = []\n",
    "    meanD = np.sort(distMart, axis=1)[:,:].mean(axis=1)\n",
    "    stdD = np.sort(distMart, axis=1)[:,:].std(axis=1)\n",
    "    \n",
    "    \n",
    "    #DIST = sklearn.metrics.pairwise.cosine_distances(X_,  X_train[-129 - 1 + i, :])\n",
    "    #print(distMart)\n",
    "    #print(meanD.shape)\n",
    "    for i1 in range(meanDist.shape[0]):\n",
    "        rr = [j for j in meanDist[i1,:]]\n",
    "        rr.append(meanD[i1])\n",
    "        rr.append(stdD[i1])\n",
    "        \n",
    "        #rr.append(DIST[i1])\n",
    "        XTrain.append(rr)\n",
    "        #print(i.shape)\n",
    "    #print(i)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = np.array(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 23)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DBSCAN_VECTOR.txt\", \"r\") as f:\n",
    "    lis = [int(i) for i in f.read().split()]\n",
    "    #print(lis)\n",
    "    XTrain = np.append(XTrain, np.array(lis).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"KMeans_matr.txt\", \"r\") as f:\n",
    "#     lis = [int(i) for i in f.read().split()]\n",
    "#     lis = np.array(lis).reshape((-1,23))  \n",
    "#     print(lis.shape, XTrain.shape)\n",
    "#     XTrain = np.append(XTrain, lis, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scl = StandardScaler()\n",
    "# scl.fit(XTrain)\n",
    "# XTrain = scl.transform(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11690, 24), (11690,))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 24)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_big_matr(matr):\n",
    "    matr1 = matr[:,:]\n",
    "    for i in range(matr.shape[1]):\n",
    "        for j in range(i, matr.shape[1]):\n",
    "                #print((matr[:,i] * matr[:,j]).shape, matr1.shape)\n",
    "                matr1 = np.concatenate((matr1, matr[:,i].reshape((-1,1)) * matr[:,j].reshape((-1,1))), axis=1)\n",
    "    return matr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XTrain = make_big_matr(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 24)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain[:texts.shape[0],:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = decomposition.TruncatedSVD(n_components=50).fit_transform(X_train)\n",
    "XTrain = np.append(XTrain,X_[:texts.shape[0],:], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_texts = data[\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(big_texts)):\n",
    "    if big_texts[i] is np.nan:\n",
    "        big_texts[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res1 = []\n",
    "# res2 = []\n",
    "# for i in np.unique(groups_train):\n",
    "#     X_ = X_train[groups_train == i]\n",
    "#     tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "#     X_ = tsne.fit_transform(X_.toarray())\n",
    "#     res1 += list(X_[:,0])\n",
    "#     res2 += list(X_[:,1])\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 74)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XTrain = np.append(XTrain, np.array(res2).reshape((-1,1)), axis=1)\n",
    "# XTrain = np.append(XTrain, np.array(res1).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\there\n",
      "0.9788321105075061\n",
      "0.8812906943477846\n",
      "(array([0, 1]), array([947, 505]))\n",
      "F1  0.8546845124282983\n",
      "\there\n",
      "0.9782040716410774\n",
      "0.8350070859600255\n",
      "(array([0, 1]), array([990, 467]))\n",
      "F1  0.731995277449823\n",
      "\there\n",
      "0.9816824995120212\n",
      "0.790192566054635\n",
      "(array([0, 1]), array([1027,  435]))\n",
      "F1  0.6920332936979785\n",
      "\there\n",
      "0.9780213621410124\n",
      "0.8190687453253325\n",
      "(array([0, 1]), array([1100,  362]))\n",
      "F1  0.736842105263158\n",
      "\there\n",
      "0.9790693370254728\n",
      "0.8547022135257429\n",
      "(array([0, 1]), array([1047,  428]))\n",
      "F1  0.7619047619047619\n",
      "\there\n",
      "0.9778901829339851\n",
      "0.8134741643437997\n",
      "(array([0, 1]), array([1036,  425]))\n",
      "F1  0.730952380952381\n",
      "\there\n",
      "0.9774087607420174\n",
      "0.8678169602388867\n",
      "(array([0, 1]), array([1001,  458]))\n",
      "F1  0.8124306326304107\n",
      "\there\n",
      "0.9815766813223332\n",
      "0.8070325492991208\n",
      "(array([0, 1]), array([1043,  419]))\n",
      "F1  0.7281323877068558\n",
      "0.833573122386916\n",
      "0.7561219190042083\n"
     ]
    }
   ],
   "source": [
    "\n",
    "folds = 8\n",
    "mean_roc_auc = 0\n",
    "mean_f1 = 0\n",
    "for train_index, test_index in GroupKFold(n_splits=folds).split(XTrain, y_train, groups_train):\n",
    "    \n",
    "    xTrain = -XTrain[train_index]\n",
    "    yTrain = y_train[train_index]\n",
    "    \n",
    "    xTest = -XTrain[test_index]\n",
    "    yTest = y_train[test_index]\n",
    "    clf = RandomForestClassifier(n_estimators=2000, \n",
    "                                 min_samples_leaf=2,\n",
    "                                 min_samples_split=4,\n",
    "                                 max_features=\"log2\",\n",
    "                                 criterion=\"entropy\",\n",
    "                                 max_depth=15,\n",
    "                                 n_jobs=-1,\n",
    "                                 class_weight=\"balanced\"\n",
    "                                    \n",
    "                                )\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    print(\"\\there\")\n",
    "    res = clf.predict(xTrain)\n",
    "    print(roc_auc_score(yTrain, res))\n",
    "    res = clf.predict(xTest)\n",
    "    print(roc_auc_score(yTest, res))\n",
    "    \n",
    "    a1 = clf.predict(xTest)\n",
    "    threeshold = np.quantile(a1, 1-p)\n",
    "    \n",
    "    mean_roc_auc += roc_auc_score(yTest, a1)\n",
    "    #print(a1, threeshold)\n",
    "    #a1 = (a1 > threeshold).astype(int)\n",
    "    print(np.unique(a1,return_counts=True))\n",
    "    print(\"F1 \", f1_score(yTest, a1))\n",
    "    mean_f1 += f1_score(yTest, a1)\n",
    "\n",
    "\n",
    "print(mean_roc_auc / folds)\n",
    "print(mean_f1 / folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1  0.7844418052256532\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 \", f1_score(y_train, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 4)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_titles = pd.read_csv(\"docs_titles.tsv\", sep=\"\\t\")\n",
    "test_groups = pd.read_csv(\"test_groups.csv\")\n",
    "table = pd.merge(test_groups, all_titles, left_on='doc_id', right_on='doc_id',how=\"left\")\n",
    "table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "      <td>КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "      <td>Скачать: SGL-RP доработка | Слив мода [MySQL] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "      <td>Как прописать админку в кс 1.6 - Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "      <td>Как прописать простую админку в кс 1 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>130</td>\n",
       "      <td>4247</td>\n",
       "      <td>Подбор админов для сервера по КОД_4 [Архив]  -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id  group_id  doc_id  \\\n",
       "0    11691       130    6710   \n",
       "1    11692       130    4030   \n",
       "2    11693       130    5561   \n",
       "3    11694       130    4055   \n",
       "4    11695       130    4247   \n",
       "\n",
       "                                               title  \n",
       "0  КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...  \n",
       "1  Скачать: SGL-RP доработка | Слив мода [MySQL] ...  \n",
       "2  Как прописать админку в кс 1.6 - Counter-Strik...  \n",
       "3             Как прописать простую админку в кс 1 6  \n",
       "4  Подбор админов для сервера по КОД_4 [Архив]  -...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_test = np.array(table[\"group_id\"])\n",
    "texts = np.array(table[\"title\"])\n",
    "for i in range(len(texts)):\n",
    "    if texts[i] is np.nan:\n",
    "        texts[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'привет  медведы   дом   жена\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem = Mystem() \n",
    "rus_stopwords = stopwords.words(\"russian\")\n",
    "eng_stopwords = stopwords.words(\"english\")\n",
    "html_stopwords = [\"span\", \"br\", \"a\", \"href\", \"img\", \"www\", \"com\", \"google\", \"ru\", \"html\", \"http\", \"https\"]\n",
    "stemming(\"Привет, медвед я в доме у  жен\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_symbols(text):\n",
    "    res = \"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    for i in text:\n",
    "        t = i    \n",
    "        if not(\n",
    "                (t >= '0' and t <= '9') or \n",
    "                (t >= 'a' and t <= 'z') or\n",
    "                (t >= 'а' and t <= 'я')\n",
    "              ):\n",
    "            t = ' '\n",
    "            \n",
    "        res += t\n",
    "        \n",
    "    return res \n",
    "\n",
    "\n",
    "def list2string(myList):  \n",
    "    myStr = \"\"  \n",
    "    \n",
    "    for word in myList:\n",
    "        if (word not in rus_stopwords) and (word not in eng_stopwords ) and (word not in html_stopwords):\n",
    "            myStr += word\n",
    "    \n",
    "    return myStr\n",
    "\n",
    "def stemming(text):\n",
    "    text = delete_symbols(text)\n",
    "    \n",
    "    tokens = mystem.lemmatize(text)\n",
    "    stri = list2string(tokens)\n",
    "    #print(stri)\n",
    "    return stri\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = []\n",
    "for i in texts:\n",
    "    new_texts.append(stemming(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X_test = vect.fit_transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_id = []\n",
    "groups_id = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neigh = 25\n",
    "XTest = []\n",
    "for i in np.unique(groups_test):\n",
    "    X_ = X_train[np.append(groups_train, groups_test) == i]\n",
    "    \n",
    "    distMart = sklearn.metrics.pairwise_distances(X_, metric=\"cosine\")\n",
    "    #print(distMart)\n",
    "    meanDist = np.sort(distMart, axis=1)[:,4:neigh]\n",
    "    lis = []\n",
    "    meanD = np.sort(distMart, axis=1)[:,:].mean(axis=1)\n",
    "    stdD = np.sort(distMart, axis=1)[:,:].std(axis=1)\n",
    "    for i in range(meanDist.shape[0]):\n",
    "        rr = [j for j in meanDist[i,:]]\n",
    "        rr.append(meanD[i])\n",
    "        rr.append(stdD[i])\n",
    "        XTest.append(rr)\n",
    "        #print(i.shape)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = np.array(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 23)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 74)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16627 (16627, 23)\n"
     ]
    }
   ],
   "source": [
    "with open(\"TEST_DBSCAN_VECTOR.txt\", \"r\") as f:\n",
    "    lis = [int(i) for i in f.read().split()]\n",
    "    print(len(lis),XTest.shape)\n",
    "    XTest = np.append(XTest, np.array(lis).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = decomposition.TruncatedSVD(n_components=50).fit_transform(X_train)\n",
    "XTest = np.append(XTest,X_[11690:,:], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 24)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "res1 = []\n",
    "res2 = []\n",
    "for i in np.unique(groups_test):\n",
    "    X_ = X_test[groups_test == i]\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    X_ = tsne.fit_transform(X_.toarray())\n",
    "    res1 += list(X_[:,0])\n",
    "    res2 += list(X_[:,1])\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = np.append(XTest, np.array(res2).reshape((-1,1)), axis=1)\n",
    "XTest = np.append(XTest, np.array(res1).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16627, 74), (11690, 74))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTest.shape, XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   1, ..., 129, 129, 129])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(pd.read_csv(\"HAHA.csv\")[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1  0.8516746411483254\n",
      "F1  0.731535756154748\n",
      "F1  0.6848989298454221\n",
      "F1  0.7351351351351351\n",
      "F1  0.7603513174404015\n",
      "F1  0.736094674556213\n",
      "F1  0.8106312292358804\n",
      "F1  0.7199046483909416\n"
     ]
    }
   ],
   "source": [
    "mean_f1 = 0\n",
    "result = []\n",
    "folds = 8\n",
    "for train_index, test_index in GroupKFold(n_splits=folds).split(X_train[:11690,:], y_train, groups_train):\n",
    "    #threeshold = 0.1\n",
    "    xTrain = XTrain[train_index]\n",
    "    yTrain = y_train[train_index]\n",
    "    \n",
    "    xTest = XTrain[test_index]\n",
    "    yTest = y_train[test_index]\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=2000, \n",
    "                                 min_samples_leaf=2,\n",
    "                                 min_samples_split=4,\n",
    "                                 max_features=\"log2\",\n",
    "                                 criterion=\"entropy\",\n",
    "                                 max_depth=15,\n",
    "                                 n_jobs=-1,\n",
    "                                 class_weight=\"balanced\"\n",
    "                                    \n",
    "                                )\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    a1 = clf.predict(XTest)\n",
    "    \n",
    "    \n",
    "    result.append(a1)\n",
    "    a1 = clf.predict(xTest)\n",
    "    print(\"F1 \", f1_score(yTest, a1))\n",
    "    mean_f1 += f1_score(yTest, a1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-144-d17ca1acc36c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(result)\n",
    "r = r.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([11689,   161,    97,    57,    72,    64,    92,   175,  4220]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(r, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([11689,   161,    97,    57,    72,    64,    92,   175,  4220]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(r, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(r.shape[0]):\n",
    "    if r[i] > 1:\n",
    "        r[i] = 1\n",
    "    else:\n",
    "        r[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2873037830035484, 0.28751069289991443)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array(r)\n",
    "r.mean(), p"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HAHA.csv\", \"w\") as f:\n",
    "    print(\"pair_id,target\", file=f)\n",
    "    for i in range(len(r)):\n",
    "        print(table[\"pair_id\"].iloc[i], \",\", r[i], file=f, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 24)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
