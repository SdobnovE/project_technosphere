{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from html_sanitizer import Sanitizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random as rnd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import bs4\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"TitlesTrain.csv\")\n",
    "data_1 = pd.read_csv(\"mean_text.csv\")\n",
    "y_train = np.array(data[\"target\"])\n",
    "groups_train = np.array(data[\"group\"])\n",
    "texts = np.array(data[\"information\"])\n",
    "texts_1 = np.array(data_1[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Inf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>information</th>\n",
       "      <th>group</th>\n",
       "      <th>target</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16 13 замена подшипник ступица ваз 21213   зам...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ваз 2107 опт      class  js link ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ступица лада калина2         ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>index   id  logo  learn center    классика...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ступица нива    провожать ремонт  замена подши...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0             0   \n",
       "1           1             1   \n",
       "2           2             2   \n",
       "3           3             3   \n",
       "4           4             4   \n",
       "\n",
       "                                         information  group  target  doc_id  \n",
       "0  16 13 замена подшипник ступица ваз 21213   зам...      1       0   15731  \n",
       "1               ваз 2107 опт      class  js link ...      1       0   14829  \n",
       "2                   ступица лада калина2         ...      1       0   15764  \n",
       "3      index   id  logo  learn center    классика...      1       0   17669  \n",
       "4  ступица нива    провожать ремонт  замена подши...      1       0   14852  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []\n",
    "# for i in range(data.shape[0]):\n",
    "#     #print(data.iloc[i][\"information\"],data.iloc[i][\"word\"])\n",
    "#     texts.append(str(data.iloc[i][\"information\"]) + \" \" + str(data.iloc[i][\"word\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.concatenate((texts,texts_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "    if texts[i] is np.nan:\n",
    "        texts[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.7065, 1.4826, 2.9652, 1.4826, 2.2239])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " a = np.array([[6, 8, 3, 0],\n",
    "...               [3, 2, 1, 7],\n",
    "...               [8, 1, 8, 4],\n",
    "...               [5, 3, 0, 5],\n",
    "...               [4, 7, 5, 9]])\n",
    "from scipy import stats\n",
    "stats.mode(a, axis=1)[0][0]\n",
    "stats.median_absolute_deviation(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X_train = vect.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neigh = 25\n",
    "XTrain = []\n",
    "for i in np.unique(groups_train):\n",
    "    X_ = X_train[groups_train == i]\n",
    "    \n",
    "    distMart = sklearn.metrics.pairwise_distances(X_, metric=\"cosine\")\n",
    "    #print(distMart)\n",
    "    meanDist = np.sort(distMart, axis=1)[:,4:neigh]\n",
    "    lis = []\n",
    "    meanD = np.sort(distMart, axis=1)[:,:].mean(axis=1)\n",
    "    stdD = np.sort(distMart, axis=1)[:,:].std(axis=1)\n",
    "    mode = np.array(stats.mode(np.sort(distMart, axis=1)[:,:], axis=1))\n",
    "    median = stats.median_absolute_deviation(np.sort(distMart, axis=1)[:,:], axis=1)\n",
    "    #print(stdD.shape, mode.shape)\n",
    "    \n",
    "    DIST = sklearn.metrics.pairwise.cosine_distances(X_,  X_train[-129 - 1 + i, :])\n",
    "    #print(distMart)\n",
    "    #print(meanD.shape)\n",
    "    for i in range(meanDist.shape[0]):\n",
    "        rr = [j for j in meanDist[i,:]]\n",
    "        \n",
    "        rr.append(meanD[i])\n",
    "        rr.append(stdD[i])\n",
    "        rr.append(DIST[i])\n",
    "        rr.append(median[i])\n",
    "        rr.append(mode[0][i])\n",
    "        rr.append(mode[1][i])\n",
    "        XTrain.append(rr)\n",
    "        #print(i.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = np.array(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 27)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DBSCAN_VECTOR.txt\", \"r\") as f:\n",
    "    lis = [int(i) for i in f.read().split()]\n",
    "    #print(lis)\n",
    "    XTrain = np.append(XTrain, np.array(lis).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 47) (11690, 28)\n"
     ]
    }
   ],
   "source": [
    "with open(\"KMeans_matr.txt\", \"r\") as f:\n",
    "    lis = [int(i) for i in f.read().split()]\n",
    "    lis = np.array(lis).reshape((-1,47))  \n",
    "    print(lis.shape, XTrain.shape)\n",
    "    XTrain = np.append(XTrain, lis, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scl = StandardScaler()\n",
    "# scl.fit(XTrain)\n",
    "# XTrain = scl.transform(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11690, 75), (11690,))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 75)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_big_matr(matr):\n",
    "    matr1 = matr[:,:]\n",
    "    for i in range(matr.shape[1]):\n",
    "        for j in range(i, matr.shape[1]):\n",
    "                #print((matr[:,i] * matr[:,j]).shape, matr1.shape)\n",
    "                matr1 = np.concatenate((matr1, matr[:,i].reshape((-1,1)) * matr[:,j].reshape((-1,1))), axis=1)\n",
    "    return matr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XTrain = make_big_matr(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 75)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(score_func=chi2, k=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = bestfeatures.fit_transform(XTrain,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\there\n",
      "0.9621905409307244\n",
      "0.8392029233987554\n",
      "(array([0, 1]), array([873, 579]))\n",
      "F1  0.7964285714285714\n",
      "\there\n",
      "0.9615791305959993\n",
      "0.7861664956262522\n",
      "(array([0, 1]), array([1042,  415]))\n",
      "F1  0.6767295597484276\n",
      "\there\n",
      "0.9657397048118308\n",
      "0.7932247350350798\n",
      "(array([0, 1]), array([1019,  443]))\n",
      "F1  0.6949352179034157\n",
      "\there\n",
      "0.9636724570442251\n",
      "0.8140560399749547\n",
      "(array([0, 1]), array([1093,  369]))\n",
      "F1  0.7272727272727273\n",
      "\there\n",
      "0.964125071782346\n",
      "0.8137458725694021\n",
      "(array([0, 1]), array([1100,  375]))\n",
      "F1  0.7194630872483221\n",
      "\there\n",
      "0.9635476426377342\n",
      "0.8306883365200765\n",
      "(array([0, 1]), array([984, 477]))\n",
      "F1  0.7443946188340808\n",
      "\there\n",
      "0.9607692067615606\n",
      "0.8648642043333747\n",
      "(array([0, 1]), array([995, 464]))\n",
      "F1  0.8070562293274532\n",
      "\there\n",
      "0.9663828521411272\n",
      "0.7902137143762233\n",
      "(array([0, 1]), array([1039,  423]))\n",
      "F1  0.7035294117647058\n",
      "0.8165202902292649\n",
      "0.733726177940963\n"
     ]
    }
   ],
   "source": [
    "folds = 8\n",
    "mean_roc_auc = 0\n",
    "mean_f1 = 0\n",
    "for train_index, test_index in GroupKFold(n_splits=folds).split(XTrain, y_train, groups_train):\n",
    "    \n",
    "    xTrain = -XTrain[train_index]\n",
    "    yTrain = y_train[train_index]\n",
    "    \n",
    "    xTest = -XTrain[test_index]\n",
    "    yTest = y_train[test_index]\n",
    "    clf = RandomForestClassifier(n_estimators=2000, \n",
    "                                 min_samples_leaf=2,\n",
    "                                 min_samples_split=4,\n",
    "                                 max_features=\"log2\",\n",
    "                                 criterion=\"entropy\",\n",
    "                                 max_depth=15,\n",
    "                                 n_jobs=-1,\n",
    "                                 class_weight=\"balanced\"\n",
    "                                    \n",
    "                                )\n",
    "    \n",
    "    clf.fit(xTrain, yTrain)\n",
    "    print(\"\\there\")\n",
    "    res = clf.predict(xTrain)\n",
    "    print(roc_auc_score(yTrain, res))\n",
    "    res = clf.predict(xTest)\n",
    "    print(roc_auc_score(yTest, res))\n",
    "    \n",
    "    a1 = clf.predict(xTest)\n",
    "    threeshold = np.quantile(a1, 1-p)\n",
    "    \n",
    "    mean_roc_auc += roc_auc_score(yTest, a1)\n",
    "    #print(a1, threeshold)\n",
    "    #a1 = (a1 > threeshold).astype(int)\n",
    "    print(np.unique(a1,return_counts=True))\n",
    "    print(\"F1 \", f1_score(yTest, a1))\n",
    "    mean_f1 += f1_score(yTest, a1)\n",
    "\n",
    "\n",
    "print(mean_roc_auc / folds)\n",
    "print(mean_f1 / folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 4)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_titles = pd.read_csv(\"docs_titles.tsv\", sep=\"\\t\")\n",
    "test_groups = pd.read_csv(\"test_groups.csv\")\n",
    "table = pd.merge(test_groups, all_titles, left_on='doc_id', right_on='doc_id',how=\"left\")\n",
    "table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "      <td>КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "      <td>Скачать: SGL-RP доработка | Слив мода [MySQL] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "      <td>Как прописать админку в кс 1.6 - Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "      <td>Как прописать простую админку в кс 1 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>130</td>\n",
       "      <td>4247</td>\n",
       "      <td>Подбор админов для сервера по КОД_4 [Архив]  -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id  group_id  doc_id  \\\n",
       "0    11691       130    6710   \n",
       "1    11692       130    4030   \n",
       "2    11693       130    5561   \n",
       "3    11694       130    4055   \n",
       "4    11695       130    4247   \n",
       "\n",
       "                                               title  \n",
       "0  КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...  \n",
       "1  Скачать: SGL-RP доработка | Слив мода [MySQL] ...  \n",
       "2  Как прописать админку в кс 1.6 - Counter-Strik...  \n",
       "3             Как прописать простую админку в кс 1 6  \n",
       "4  Подбор админов для сервера по КОД_4 [Архив]  -...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_test = np.array(table[\"group_id\"])\n",
    "texts = np.array(table[\"title\"])\n",
    "for i in range(len(texts)):\n",
    "    if texts[i] is np.nan:\n",
    "        texts[i] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_symbols(text):\n",
    "    res = \"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    for i in text:\n",
    "        t = i    \n",
    "        if not(\n",
    "                (t >= '0' and t <= '9') or \n",
    "                (t >= 'a' and t <= 'z') or\n",
    "                (t >= 'а' and t <= 'я')\n",
    "              ):\n",
    "            t = ' '\n",
    "            \n",
    "        res += t\n",
    "        \n",
    "    return res \n",
    "\n",
    "\n",
    "def list2string(myList):  \n",
    "    myStr = \"\"  \n",
    "    \n",
    "    for word in myList:\n",
    "        if (word not in rus_stopwords) and (word not in eng_stopwords ) and (word not in html_stopwords):\n",
    "            myStr += word\n",
    "    \n",
    "    return myStr\n",
    "\n",
    "def stemming(text):\n",
    "    text = delete_symbols(text)\n",
    "    \n",
    "    tokens = mystem.lemmatize(text)\n",
    "    stri = list2string(tokens)\n",
    "    #print(stri)\n",
    "    return stri\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'привет  медведы   дом   жена\\n'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem = Mystem() \n",
    "rus_stopwords = stopwords.words(\"russian\")\n",
    "eng_stopwords = stopwords.words(\"english\")\n",
    "html_stopwords = [\"span\", \"br\", \"a\", \"href\", \"img\", \"www\", \"com\", \"google\", \"ru\", \"html\", \"http\", \"https\"]\n",
    "stemming(\"Привет, медвед я в доме у  жен\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = []\n",
    "for i in texts:\n",
    "    new_texts.append(stemming(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "X_test = vect.fit_transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_id = []\n",
    "groups_id = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = 25\n",
    "XTrain = []\n",
    "for i in np.unique(groups_train):\n",
    "    X_ = X_train[groups_train == i]\n",
    "    \n",
    "    distMart = sklearn.metrics.pairwise_distances(X_, metric=\"cosine\")\n",
    "    #print(distMart)\n",
    "    meanDist = np.sort(distMart, axis=1)[:,4:neigh]\n",
    "    lis = []\n",
    "    meanD = np.sort(distMart, axis=1)[:,:].mean(axis=1)\n",
    "    stdD = np.sort(distMart, axis=1)[:,:].std(axis=1)\n",
    "    \n",
    "    \n",
    "    DIST = sklearn.metrics.pairwise.cosine_distances(X_,  X_train[-129 - 1 + i, :])\n",
    "    #print(distMart)\n",
    "    #print(meanD.shape)\n",
    "    for i in range(meanDist.shape[0]):\n",
    "        rr = [j for j in meanDist[i,:]]\n",
    "        rr.append(meanD[i])\n",
    "        rr.append(stdD[i])\n",
    "        #rr.append(DIST[i])\n",
    "        XTrain.append(rr)\n",
    "        #print(i.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neigh = 25\n",
    "XTest = []\n",
    "for i in np.unique(groups_test):\n",
    "    X_ = X_test[groups_test == i]\n",
    "    \n",
    "    distMart = sklearn.metrics.pairwise_distances(X_, metric=\"cosine\")\n",
    "    #print(distMart)\n",
    "    meanDist = np.sort(distMart, axis=1)[:,4:neigh]\n",
    "    lis = []\n",
    "    meanD = np.sort(distMart, axis=1)[:,:].mean(axis=1)\n",
    "    stdD = np.sort(distMart, axis=1)[:,:].std(axis=1)\n",
    "    for i in range(meanDist.shape[0]):\n",
    "        rr = [j for j in meanDist[i,:]]\n",
    "        rr.append(meanD[i])\n",
    "        rr.append(stdD[i])\n",
    "        rr.append(maxD[i])\n",
    "        rr.append(minD[i])\n",
    "        XTest.append(rr)\n",
    "        #print(i.shape)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = np.array(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16627 (16627, 25)\n"
     ]
    }
   ],
   "source": [
    "with open(\"TEST_DBSCAN_VECTOR.txt\", \"r\") as f:\n",
    "    lis = [int(i) for i in f.read().split()]\n",
    "    print(len(lis),XTest.shape)\n",
    "    XTest = np.append(XTest, np.array(lis).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11690, 377), (16627, 377))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape, XTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = make_big_matr(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[1 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "[0 0 0 ... 1 1 1]\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.000000000001\n",
    "max_epoch = 500\n",
    "C = 0.2\n",
    "batch_size = 450\n",
    "folds = 8\n",
    "res = []\n",
    "threeshold = 0.30\n",
    "mean_roc_auc = 0\n",
    "mean_f1 = 0\n",
    "result = []\n",
    "for train_index, test_index in GroupKFold(n_splits=folds).split(X_train, y_train, groups_train):\n",
    "    #threeshold = 0.1\n",
    "    xTrain = XTrain[train_index]\n",
    "    yTrain = y_train[train_index]\n",
    "    \n",
    "    xTest = XTrain[test_index]\n",
    "    yTest = y_train[test_index]\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=2000, \n",
    "                                 min_samples_leaf=2,\n",
    "                                 min_samples_split=4,\n",
    "                                 max_features=\"log2\",\n",
    "                                 criterion=\"entropy\",\n",
    "                                 max_depth=15,\n",
    "                                 n_jobs=-1,\n",
    "                                 class_weight=\"balanced\"\n",
    "                                    \n",
    "                                )\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    a1 = clf.predict(XTest)\n",
    "    \n",
    "    \n",
    "    threshold = np.quantile(a1, 1-p)\n",
    "    \n",
    "    a1 = (a1 > threeshold).astype(int)\n",
    "    result.append(a1)\n",
    "\n",
    "\n",
    "print(mean_roc_auc / folds)\n",
    "print(mean_f1 / folds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(result)\n",
    "r = r.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = 2\n",
    "for i in range(r.shape[0]):\n",
    "    if r[i] > 5:\n",
    "        r[i] = 1\n",
    "    else:\n",
    "        r[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.27671859024478257, 0.28751069289991443)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.array(r)\n",
    "r.mean(), p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_submission2.csv\", \"w\") as f:\n",
    "    print(\"pair_id,target\", file=f)\n",
    "    for i in range(len(r)):\n",
    "        print(table[\"pair_id\"].iloc[i], \",\", r[i], file=f, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.57606601],\n",
       "       [0.57606601, 1.        ]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(XTrain[:,23],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 24)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
