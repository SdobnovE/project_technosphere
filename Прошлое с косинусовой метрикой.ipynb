{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from html_sanitizer import Sanitizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import random as rnd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Inf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(data[\"target\"])\n",
    "groups_train = np.array(data[\"group\"])\n",
    "texts = np.array(data[\"information\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11690"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "    if texts[i] is np.nan:\n",
    "        texts[i] = \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=7, max_df=0.4)\n",
    "X_train = vect.fit_transform(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train1 = []\n",
    "# for i in range(texts.shape[0]):\n",
    "#     print(i)\n",
    "#     cur_grp = groups_train[i]\n",
    "#     words = set(texts[i].strip().split())\n",
    "#     all_dist = []\n",
    "#     #print(texts[groups_train == cur_grp])\n",
    "#     for j in range(len(texts[groups_train == cur_grp])):\n",
    "#         if i == j:\n",
    "#             continue\n",
    "        \n",
    "        \n",
    "        \n",
    "#         words_j = set(texts[j].strip().split())\n",
    "#         all_dist.append(len(words.intersection(words_j)))\n",
    "#     X_train1.append(sorted(all_dist, reverse=True)[0:15]    )\n",
    "# X_train1 = np.array(X_train1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neigh = 26\n",
    "XTrain = []\n",
    "for i in np.unique(groups_train):\n",
    "    X_ = X_train[groups_train == i]\n",
    "    \n",
    "    distMart = sklearn.metrics.pairwise_distances(X_, metric=\"cosine\")\n",
    "    #print(distMart)\n",
    "    meanDist = np.sort(distMart, axis=1)[:,1:neigh]\n",
    "    lis = []\n",
    "    #print(meanDist)\n",
    "    for i in meanDist:\n",
    "        XTrain.append(list(i))\n",
    "        #print(i.shape)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = np.array(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11690\n"
     ]
    }
   ],
   "source": [
    "with open(\"DBSCAN_VECTOR.txt\", \"r\") as f:\n",
    "    lis = [int(i) for i in f.read().split()]\n",
    "    print(len(lis))\n",
    "    XTrain = np.append(XTrain[:,0:17], np.array(lis).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = StandardScaler()\n",
    "scl.fit(XTrain)\n",
    "XTrain = scl.transform(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11690, 18)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1452, 18) (19,)\n",
      "Roc  0.8436839937425307\n",
      "[0.45717699 0.33562236 0.3690735  ... 0.10769141 0.11361731 0.12047619]\n",
      "(1457, 18) (19,)\n",
      "Roc  0.8674375702487416\n",
      "[0.33106534 0.34152324 0.07227599 ... 0.75687192 0.69278013 0.59866855]\n",
      "(1462, 18) (19,)\n",
      "Roc  0.8433080030601583\n",
      "[0.13322359 0.13119109 0.17410008 ... 0.22824141 0.1841898  0.22567161]\n",
      "(1462, 18) (19,)\n",
      "Roc  0.8981379291862485\n",
      "[0.11887374 0.16224319 0.11887374 ... 0.57989782 0.73884728 0.33851585]\n",
      "(1475, 18) (19,)\n",
      "Roc  0.8769988993518406\n",
      "[0.08227002 0.08715222 0.24372697 ... 0.73098729 0.58556957 0.8389528 ]\n",
      "(1461, 18) (19,)\n",
      "Roc  0.9075283927296184\n",
      "[0.09244216 0.12896166 0.13082494 ... 0.17893192 0.1695244  0.54661704]\n",
      "(1459, 18) (19,)\n",
      "Roc  0.9235438403156717\n",
      "[0.12313705 0.11169155 0.11996935 ... 0.18029006 0.12838655 0.18386575]\n",
      "(1462, 18) (19,)\n",
      "Roc  0.8580943330052383\n",
      "[0.06161956 0.35912591 0.08323116 ... 0.72283761 0.69252705 0.6475501 ]\n",
      "0.8773416202050061\n",
      "0.701397545467939\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.000000000001\n",
    "max_epoch = 500\n",
    "C = 0.5\n",
    "batch_size = 450\n",
    "folds = 8\n",
    "res = []\n",
    "threeshold = 0.30\n",
    "mean_roc_auc = 0\n",
    "mean_f1 = 0\n",
    "\n",
    "for train_index, test_index in GroupKFold(n_splits=folds).split(X_train, y_train, groups_train):\n",
    "    #threeshold = 0.1\n",
    "    xTrain = XTrain[train_index]\n",
    "    yTrain = y_train[train_index]\n",
    "    \n",
    "    xTest = XTrain[test_index]\n",
    "    yTest = y_train[test_index]\n",
    "    \n",
    "    clf = MySGDClassifier(batch_generator, C=C, max_epoch=max_epoch, \n",
    "                      model_type=\"log_reg\",batch_size=batch_size)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    a1 = clf.predict(xTest)\n",
    "    \n",
    "    \n",
    "    threshold = np.quantile(a1, 1-p)\n",
    "    print(\"Roc \", roc_auc_score(yTest, a1))\n",
    "    print(a1)\n",
    "    mean_roc_auc += roc_auc_score(yTest, a1)\n",
    "    \n",
    "    a1 = (a1 > threeshold).astype(int)\n",
    "    #print(np.unique(a1, return_counts=True))\n",
    "    #print(np.unique(a1, return_counts=True)[1][0] / np.unique(a1, return_counts=True)[1][1])\n",
    "    mean_f1 += f1_score(yTest, a1)\n",
    "#     print(a2)\n",
    "#     for i in range(40):\n",
    "#         print(\"f1\", f1_score(yTest, (a1 > threeshold).astype(int)), threeshold)\n",
    "#         threeshold+=0.01\n",
    "\n",
    "print(mean_roc_auc / folds)\n",
    "print(mean_f1 / folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Вычисляем значение сигмоида.\n",
    "    X - выход линейной модели\n",
    "    \"\"\"\n",
    "    \n",
    "    sigm_value_x = 1. / (1 + np.exp(-x))\n",
    "    return sigm_value_x\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class MySGDClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, batch_generator, C=1, alpha=0.01, \n",
    "                 max_epoch=10, model_type='lin_reg',\n",
    "                batch_size=1):\n",
    "        \"\"\"\n",
    "        batch_generator -- функция генератор, которой будем создавать батчи\n",
    "        C - коэф. регуляризации\n",
    "        alpha - скорость спуска\n",
    "        max_epoch - максимальное количество эпох\n",
    "        model_type - тип модели, lin_reg или log_reg\n",
    "        \"\"\"\n",
    "        if model_type != 'lin_reg' and model_type != 'log_reg':\n",
    "            raise TypeError\n",
    "            \n",
    "        self.batch_size = batch_size   \n",
    "        self.C = C\n",
    "        self.alpha = alpha\n",
    "        self.max_epoch = max_epoch\n",
    "        self.batch_generator = batch_generator\n",
    "        self.errors_log = {'iter' : [], 'loss' : []}  \n",
    "        self.model_type = model_type\n",
    "        \n",
    "    def calc_loss(self, X_batch, y_batch):#############\n",
    "        \"\"\"\n",
    "        Считаем функцию потерь по батчу \n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        \n",
    "        loss = 0\n",
    "        if self.model_type == 'log_reg':\n",
    "            p = sigmoid(np.dot(X_batch, self.weights))\n",
    "            if p < 1e-16:\n",
    "                p = 0.0001\n",
    "            \n",
    "            if 1 - p < 1e-16:\n",
    "                p = 0.9999\n",
    "                \n",
    "            loss = np.dot(y_batch, np.log(p))\n",
    "            loss += np.dot(1 - y_batch, np.log(1 - p))\n",
    "            loss *= -1\n",
    "            loss /= y_batch.shape[0]\n",
    "        \n",
    "        else:\n",
    "            loss = ((y_batch - np.dot(X_batch, self.weights)) ** 2).sum()\n",
    "            loss /= y_batch.shape[0]\n",
    "            \n",
    "        return loss \n",
    "    \n",
    "    \n",
    "    def calc_loss_grad(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Считаем  градиент функции потерь по батчу (то что Вы вывели в задании 1)\n",
    "        X_batch - матрица объекты-признаки по батчу\n",
    "        y_batch - вектор ответов по батчу\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        \"\"\"\n",
    "        loss_grad = 0\n",
    "        if self.model_type == 'lin_reg':\n",
    "            loss_grad = np.dot(X_batch, self.weights) \n",
    "            loss_grad -= y_batch\n",
    "            loss_grad = np.dot(X_batch.transpose(), loss_grad)\n",
    "            loss_grad /= y_batch.shape[0]\n",
    "            \n",
    "            temp = self.weights[0]\n",
    "            self.weights[0] = 0.\n",
    "            loss_grad += self.C * self.weights\n",
    "            self.weights[0] = temp\n",
    "                \n",
    "            loss_grad *= 2\n",
    "            \n",
    "        else:\n",
    "            V = sigmoid(np.dot(X_batch, self.weights))\n",
    "            loss_grad = V - y_batch\n",
    "            loss_grad = np.dot(X_batch.transpose(), loss_grad)\n",
    "            loss_grad /= y_batch.shape[0]\n",
    "            \n",
    "            temp = self.weights[0]\n",
    "            self.weights[0] = 0.\n",
    "            loss_grad += 2 * self.C * self.weights\n",
    "            self.weights[0] = temp\n",
    "         \n",
    "        return loss_grad\n",
    "    \n",
    "    def update_weights(self, new_grad):####################\n",
    "        \"\"\"\n",
    "        Обновляем вектор весов\n",
    "        new_grad - градиент по батчу\n",
    "        \"\"\"\n",
    "        self.weights -= new_grad * self.alpha\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Обучение модели\n",
    "        X - матрица объекты-признаки\n",
    "        y - вектор ответов\n",
    "        '''\n",
    "        \n",
    "        # Нужно инициализровать случайно веса\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        ones = np.array([1 for i in range(X.shape[0])]).reshape((-1,1))\n",
    "        X = np.concatenate((ones, X), axis=1)\n",
    "        \n",
    "        self.weights = np.random.uniform(-10, 10, X.shape[1])\n",
    "        for n in range(0, self.max_epoch):\n",
    "            new_epoch_generator = self.batch_generator(X, y)\n",
    "            iterator = 0\n",
    "            for batch_num, new_batch in new_epoch_generator:\n",
    "                X_batch = new_batch[0]\n",
    "                \n",
    "                y_batch = new_batch[1]\n",
    "                batch_grad = self.calc_loss_grad(X_batch, y_batch)\n",
    "                \n",
    "                self.update_weights(batch_grad)\n",
    "                batch_loss = self.calc_loss(X_batch, y_batch)\n",
    "                \n",
    "                self.errors_log['iter'].append(batch_num)\n",
    "                self.errors_log['loss'].append(batch_loss)\n",
    "                \n",
    "                if iterator > X.shape[0] / self.batch_size:\n",
    "                    break\n",
    "                iterator+=1\n",
    "                \n",
    "                \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Предсказание класса\n",
    "        X - матрица объекты-признаки\n",
    "        Не забудте тип модели (линейная или логистическая регрессия)!\n",
    "        '''\n",
    "        print(X.shape, self.weights.shape)\n",
    "        y_hat = 0\n",
    "        if self.model_type == \"lin_reg\":\n",
    "            y_hat = np.dot(X, self.weights[1:]) + self.weights[0]\n",
    "        \n",
    "        else:\n",
    "            y_hat = sigmoid(np.dot(X, self.weights[1:]) + self.weights[0])\n",
    "        # Желательно здесь использовать матричные операции между X и весами, например, numpy.dot \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, shuffle=True, batch_size=1):\n",
    "    \"\"\"\n",
    "    Гератор новых батчей для обучения\n",
    "    X          - матрица объекты-признаки\n",
    "    y_batch    - вектор ответов\n",
    "    shuffle    - нужно ли случайно перемешивать выборку\n",
    "    batch_size - размер батча ( 1 это SGD, > 1 mini-batch GD)\n",
    "    Генерирует подвыборку для итерации спуска (X_batch, y_batch)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_batch = \"\"\n",
    "    y_batch = \"\"\n",
    "    num = 0\n",
    "    if shuffle == True:\n",
    "        while True:\n",
    "            \n",
    "            ind = rnd.sample([i for i in range(X.shape[0])], batch_size)\n",
    "            yield (num, (X[ind,:], y[ind]))\n",
    "            num += 1\n",
    "            \n",
    "    else:\n",
    "        i = 0\n",
    "        n = X.shape[0]\n",
    "        while True:\n",
    "            ind = [t % n for t in range(i, i + batch_size)]\n",
    "            i += batch_size\n",
    "            yield (num, (X[ind,:], y[ind]))\n",
    "            num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28751069289991443"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = pd.read_csv(\"docs_titles.tsv\", sep=\"\\t\")\n",
    "test_groups = pd.read_csv(\"test_groups.csv\")\n",
    "#table = test_groups.join(all_titles, lsuffix='_caller', rsuffix='_other', on=\"doc_id\", how=\"inner\")[[\"doc_id_caller\",\"doc_id_other\",\"pair_id\", \"group_id\",\"title\"]]\n",
    "#table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16627, 4)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.merge(test_groups, all_titles, left_on='doc_id', right_on='doc_id',how=\"left\")\n",
    "table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "      <td>КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "      <td>Скачать: SGL-RP доработка | Слив мода [MySQL] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "      <td>Как прописать админку в кс 1.6 - Counter-Strik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "      <td>Как прописать простую админку в кс 1 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>130</td>\n",
       "      <td>4247</td>\n",
       "      <td>Подбор админов для сервера по КОД_4 [Архив]  -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_id  group_id  doc_id  \\\n",
       "0    11691       130    6710   \n",
       "1    11692       130    4030   \n",
       "2    11693       130    5561   \n",
       "3    11694       130    4055   \n",
       "4    11695       130    4247   \n",
       "\n",
       "                                               title  \n",
       "0  КАК ПРОПИСАТЬ АДМИНКУ В КС 1.6 СЕБЕ ИЛИ ДРУГУ ...  \n",
       "1  Скачать: SGL-RP доработка | Слив мода [MySQL] ...  \n",
       "2  Как прописать админку в кс 1.6 - Counter-Strik...  \n",
       "3             Как прописать простую админку в кс 1 6  \n",
       "4  Подбор админов для сервера по КОД_4 [Архив]  -...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_test = np.array(table[\"group_id\"])\n",
    "texts = np.array(table[\"title\"])\n",
    "for i in range(len(texts)):\n",
    "    if texts[i] is np.nan:\n",
    "        texts[i] = \"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'привет  медведы   дом   жена\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem = Mystem() \n",
    "rus_stopwords = stopwords.words(\"russian\")\n",
    "eng_stopwords = stopwords.words(\"english\")\n",
    "html_stopwords = [\"span\", \"br\", \"a\", \"href\", \"img\", \"www\", \"com\", \"google\", \"ru\", \"html\", \"http\", \"https\"]\n",
    "stemming(\"Привет, медвед я в доме у  жен\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_symbols(text):\n",
    "    res = \"\"\n",
    "    text = text.lower()\n",
    "    \n",
    "    for i in text:\n",
    "        t = i    \n",
    "        if not(\n",
    "                (t >= '0' and t <= '9') or \n",
    "                (t >= 'a' and t <= 'z') or\n",
    "                (t >= 'а' and t <= 'я')\n",
    "              ):\n",
    "            t = ' '\n",
    "            \n",
    "        res += t\n",
    "        \n",
    "    return res \n",
    "\n",
    "\n",
    "def list2string(myList):  \n",
    "    myStr = \"\"  \n",
    "    \n",
    "    for word in myList:\n",
    "        if (word not in rus_stopwords) and (word not in eng_stopwords ) and (word not in html_stopwords):\n",
    "            myStr += word\n",
    "    \n",
    "    return myStr\n",
    "\n",
    "def stemming(text):\n",
    "    text = delete_symbols(text)\n",
    "    \n",
    "    tokens = mystem.lemmatize(text)\n",
    "    stri = list2string(tokens)\n",
    "    #print(stri)\n",
    "    return stri\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = []\n",
    "for i in texts:\n",
    "    new_texts.append(stemming(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(min_df=5, max_df=0.5)\n",
    "X_test = vect.fit_transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_id = []\n",
    "groups_id = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neigh = 26\n",
    "XTest = []\n",
    "for i in np.unique(groups_test):\n",
    "    X_ = X_test[groups_test == i]\n",
    "    \n",
    "    distMart = sklearn.metrics.pairwise_distances(X_, metric=\"cosine\")\n",
    "    #print(distMart)\n",
    "    meanDist = np.sort(distMart, axis=1)[:,1:neigh]\n",
    "    \n",
    "    for i in meanDist:\n",
    "        XTest.append(list(i))\n",
    "        #print(i.shape)\n",
    "        \n",
    "    \n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = np.array(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16627 (16627, 25)\n"
     ]
    }
   ],
   "source": [
    "with open(\"TEST_DBSCAN_VECTOR.txt\", \"r\") as f:\n",
    "    lis = [int(i) for i in f.read().split()]\n",
    "    print(len(lis),XTest.shape)\n",
    "    XTest = np.append(XTest[:,0:17], np.array(lis).reshape((-1,1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTest = scl.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16627, 18) (19,)\n",
      "(16627, 18) (19,)\n",
      "(16627, 18) (19,)\n",
      "(16627, 18) (19,)\n",
      "(16627, 18) (19,)\n",
      "(16627, 18) (19,)\n",
      "(16627, 18) (19,)\n",
      "(16627, 18) (19,)\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.000000000001\n",
    "max_epoch = 500\n",
    "C = 0.5\n",
    "batch_size = 450\n",
    "folds = 8\n",
    "res = []\n",
    "threeshold = 0.3\n",
    "mean_roc_auc = 0\n",
    "mean_f1 = 0\n",
    "res = []\n",
    "r = []\n",
    "for train_index, test_index in GroupKFold(n_splits=folds).split(XTrain, y_train, groups_train):\n",
    "    #threeshold = 0.1\n",
    "    xTrain = XTrain[train_index]\n",
    "    yTrain = y_train[train_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    clf = MySGDClassifier(batch_generator, C=C, max_epoch=max_epoch, \n",
    "                      model_type=\"log_reg\",batch_size=batch_size)\n",
    "    clf.fit(xTrain, yTrain)\n",
    "    a1 = clf.predict(XTest)\n",
    "    threeshold = np.quantile(a1, 0.27)\n",
    "    \n",
    "    #print(a1)\n",
    "    a1 = (a1 > threeshold).astype(int)\n",
    "    #print(np.unique(a1, return_counts=True))\n",
    "    #print(np.unique(a1, return_counts=True)[1][0] / np.unique(a1, return_counts=True)[1][1])\n",
    "#     print(yTrain.shape, a1.shape)\n",
    "    #print(\"Roc \", roc_auc_score(yTest, a1))\n",
    "    res.append(a1)\n",
    "    #mean_roc_auc += roc_auc_score(yTest, a1)\n",
    "    #mean_f1 += f1_score(yTest, (a1 > threeshold).astype(int))\n",
    "\n",
    "    \n",
    "\n",
    "print(mean_roc_auc / folds)\n",
    "print(mean_f1 / folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([ 4490, 12137]))\n",
      "(array([0, 1]), array([ 4490, 12137]))\n",
      "(array([0, 1]), array([ 4490, 12137]))\n",
      "(array([0, 1]), array([ 4490, 12137]))\n",
      "(array([0, 1]), array([ 4490, 12137]))\n",
      "(array([0, 1]), array([ 4490, 12137]))\n",
      "(array([0, 1]), array([ 4490, 12137]))\n",
      "(array([0, 1]), array([ 4490, 12137]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(folds):\n",
    "    print(np.unique(res[i], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12137,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][res[0]!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = np.zeros((16627,))\n",
    "for i in res:\n",
    "    res1 += i\n",
    "    \n",
    "res1 = (res1 > 5).astype(int)\n",
    "res = res1\n",
    "with open(\"my_submission2.csv\", \"w\") as f:\n",
    "    print(\"pair_id,target\", file=f)\n",
    "    for i in range(len(res)):\n",
    "        print(table[\"pair_id\"].iloc[i], \",\", res[i], file=f, sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11520,)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res!=1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][res[0]!=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.33936409, 0.46239349, 0.47242415, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.66392517, 0.68379423, 0.69208193, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.19342149, 0.20520456, 0.21564475, ..., 0.46177163, 0.47142318,\n",
       "        0.47142318],\n",
       "       [0.        , 0.22669694, 0.26326191, ..., 0.47526927, 0.49494703,\n",
       "        0.51108142],\n",
       "       [0.28213007, 0.28262285, 0.34750365, ..., 0.49420106, 0.50914478,\n",
       "        0.50991972]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [94  8]\n",
      "[0 1] [80 14]\n",
      "[0 1] [89  9]\n",
      "[0 1] [81  7]\n",
      "[0 1] [99  9]\n",
      "[0 1] [25 46]\n",
      "[0 1] [89  7]\n",
      "[0 1] [65 26]\n",
      "[0 1] [12 19]\n",
      "[0 1] [84 13]\n",
      "[0 1] [90  8]\n",
      "[0 1] [59  6]\n",
      "[0 1] [16 15]\n",
      "[0 1] [74 18]\n",
      "[0 1] [93  8]\n",
      "[0 1] [51 43]\n",
      "[0 1] [29 73]\n",
      "[0 1] [74 15]\n",
      "[0 1] [83  7]\n",
      "[0 1] [90  5]\n",
      "[0 1] [89 11]\n",
      "[0 1] [12 75]\n",
      "[0 1] [39 54]\n",
      "[0 1] [52 50]\n",
      "[0 1] [11 73]\n",
      "[0 1] [ 5 74]\n",
      "[0 1] [93  7]\n",
      "[0 1] [85  6]\n",
      "[0 1] [92  7]\n",
      "[0 1] [95  9]\n",
      "[0 1] [85 10]\n",
      "[0 1] [96  9]\n",
      "[0 1] [ 5 88]\n",
      "[0 1] [44 54]\n",
      "[0 1] [89 10]\n",
      "[0 1] [29 74]\n",
      "[0 1] [16 42]\n",
      "[0 1] [75 29]\n",
      "[0 1] [92  7]\n",
      "[0 1] [92  6]\n",
      "[0 1] [59  6]\n",
      "[0 1] [29 74]\n",
      "[0 1] [87  6]\n",
      "[0 1] [80  8]\n",
      "[0 1] [46 37]\n",
      "[0 1] [90  7]\n",
      "[0 1] [84 10]\n",
      "[0 1] [33 22]\n",
      "[0 1] [ 7 93]\n",
      "[0 1] [ 6 82]\n",
      "[0 1] [95  5]\n",
      "[0 1] [25 74]\n",
      "[0 1] [10 16]\n",
      "[0 1] [92  8]\n",
      "[0 1] [88  7]\n",
      "[0 1] [84  8]\n",
      "[0 1] [75 13]\n",
      "[0 1] [92  6]\n",
      "[0 1] [99  4]\n",
      "[0 1] [11 70]\n",
      "[0 1] [87  6]\n",
      "[0 1] [100   5]\n",
      "[0 1] [81  5]\n",
      "[0 1] [86 10]\n",
      "[0 1] [83  9]\n",
      "[0 1] [86  5]\n",
      "[0 1] [45 47]\n",
      "[0 1] [92 12]\n",
      "[0 1] [40 64]\n",
      "[0 1] [95  7]\n",
      "[0 1] [55 35]\n",
      "[0 1] [70 13]\n",
      "[0 1] [95  7]\n",
      "[0 1] [98  4]\n",
      "[0 1] [98  6]\n",
      "[0 1] [30 19]\n",
      "[0 1] [ 3 97]\n",
      "[0 1] [89  7]\n",
      "[0 1] [91  9]\n",
      "[0 1] [17 41]\n",
      "[0 1] [82 18]\n",
      "[0 1] [89  6]\n",
      "[0 1] [26 26]\n",
      "[0 1] [82 21]\n",
      "[0 1] [35 67]\n",
      "[0 1] [38 63]\n",
      "[0 1] [ 7 60]\n",
      "[0 1] [34  9]\n",
      "[0 1] [82  8]\n",
      "[0 1] [87 13]\n",
      "[0 1] [14 33]\n",
      "[0 1] [96  6]\n",
      "[0 1] [97  7]\n",
      "[0 1] [95  8]\n",
      "[0 1] [91  8]\n",
      "[0 1] [93  4]\n",
      "[0 1] [57 37]\n",
      "[0 1] [94  6]\n",
      "[0 1] [70 33]\n",
      "[0 1] [ 5 72]\n",
      "[0 1] [74 27]\n",
      "[0 1] [98  8]\n",
      "[0 1] [94  8]\n",
      "[0 1] [96  8]\n",
      "[0 1] [79  9]\n",
      "[0 1] [95  6]\n",
      "[0 1] [88  5]\n",
      "[0 1] [88  7]\n",
      "[0 1] [99  8]\n",
      "[0 1] [30 73]\n",
      "[0 1] [87 13]\n",
      "[0 1] [96  9]\n",
      "[0 1] [101   4]\n",
      "[0 1] [73  8]\n",
      "[0 1] [22 39]\n",
      "[0 1] [85  8]\n",
      "[0 1] [98  9]\n",
      "[0 1] [39 55]\n",
      "[0 1] [28 49]\n",
      "[0 1] [ 9 31]\n",
      "[0 1] [ 8 91]\n",
      "[0 1] [70 24]\n",
      "[0 1] [19 69]\n",
      "[0 1] [18 89]\n",
      "[0 1] [86  8]\n",
      "[0 1] [10 93]\n",
      "[0 1] [70 31]\n",
      "[0 1] [ 7 43]\n",
      "[0 1] [82  9]\n"
     ]
    }
   ],
   "source": [
    "neigh = 26\n",
    "XTest = []\n",
    "res = []\n",
    "for i in np.unique(groups_train):\n",
    "    y_ = y_train[groups_train == i]\n",
    "    elem, cnt = np.unique(y_train[groups_train == i], return_counts=True)\n",
    "    print(elem,cnt)\n",
    "    if cnt[0] != 0:\n",
    "        res.append(cnt[0]/cnt[1])\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "#XTrain = np.array(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.545438304536387"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(res).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
